{"test_precision":0.75,"test_accuracy":0.75,"test_ap":0.9306,"test_recall":1,"test_auc":0.75,"train_auc":0.9962,"train_f1":0.972,"validation_accuracy":0.8571,"recall_comparison_plot_table":{"nrows":243,"_type":"table-file","sha256":"c1395fed20a6b1d0918cbad6d52166d6bdad06a7c416dde4afe5aa37f8e0ceda","size":5213,"artifact_path":"wandb-client-artifact://fbzhi6zn32f1rdssu19acqxn4hc2t1e0zo23bceytx4tx8omsgqxqkoruetheth6lk10dvs89h2xd3ya5d9pmvv0d7arl49347r1j06bzpsjpzvkqy7yxi13ryuw7sdy/recall_comparison_plot_table.table.json","_latest_artifact_path":"wandb-client-artifact://9y3ptgvrs915tp7sdbpe1236f0nl2s62nirhpnfhxlmcc2vg6mym8jhmuj97kf3wzx3ci9p7p8bpqkfx367lfm0ljp4h4i6sg97xh69b0fh9wz8v42cn4dc61g753f57:latest/recall_comparison_plot_table.table.json","path":"media/table/recall_comparison_plot_table_491_c1395fed20a6b1d0918c.table.json","ncols":3},"f1_comparison_plot_table":{"_type":"table-file","sha256":"e677460cb20272e58e3cd8db03b2840b5f4ace92e7ce20bb7c12a1ce71301e45","size":5916,"artifact_path":"wandb-client-artifact://828k4eehj8lu00qop17vdf2yx6vwmgybrhuiwjto7jusbwqivbcbn7hmkpixyk53abxrxkit3lqyllyuiduxv1hi2lukpa4j5xbpra64ku4m2g28pk30fpds0h7zbf1h/f1_comparison_plot_table.table.json","_latest_artifact_path":"wandb-client-artifact://k3xs491smlnct9uhxbyym891rn59anelc2rctid3wd2pwss1koqfw7zhrxszlsxv2wfkr64w72on1tbb5frrqqu5lcvviba37823lh0cwugotllszvphpgw9jg2mfrhc:latest/f1_comparison_plot_table.table.json","path":"media/table/f1_comparison_plot_table_489_e677460cb20272e58e3c.table.json","ncols":3,"nrows":243},"auc_comparison_plot_table":{"artifact_path":"wandb-client-artifact://m3gzz4o5oashceaodtdwahvbggi58uu3cmke400dyqurlu07rgt8bb7i12fmyc2hj6cyv2qjhkpu39jvolpne0pobg6ow7q0exezi6wuk3gddb9yof2dajme18ypjxgl/auc_comparison_plot_table.table.json","_latest_artifact_path":"wandb-client-artifact://uxg5l2gdgw5qdewyqh3q7hoisk2y9fwfub9f959e3rkbosr8raj0l5ff9j3nmg38c4rdz6iht6ocqv2vjuxq0m0v7526wlzjs7kyr5onap59ggfzvo1uhlfvlyl0tfxd:latest/auc_comparison_plot_table.table.json","path":"media/table/auc_comparison_plot_table_488_8477084889aa89e89294.table.json","ncols":3,"nrows":243,"_type":"table-file","sha256":"8477084889aa89e89294b599954add9a0ccd1027c9bf618e828107aedb32d99e","size":5822},"train_accuracy":0.9474,"_runtime":59.369292611,"precision_comparison_plot_table":{"sha256":"5d9819d5d11836f365bb394f7d1917c2a121adaab91adfb760c751a171c8890b","size":5773,"artifact_path":"wandb-client-artifact://ijfsvvyzg7sod1dmismy8t2emx3s20l5fmzfhtxr661egqimy3trigrbitnwkhj51zf43wmhbd6mqpnxvsddips6ub0uduxdy5olzbvbh95huqjfrk7rmyolvs7p16vd/precision_comparison_plot_table.table.json","_latest_artifact_path":"wandb-client-artifact://gpxm3t1x8agt8wb0jii84vd7jd63wd49hxldspbt6accsckz2cj19en6xgst80wa461n23jy9r8u823mmrkweof5dz0i1paq8uqago8i28rknlk2s102ud8cikykzgug:latest/precision_comparison_plot_table.table.json","path":"media/table/precision_comparison_plot_table_490_5d9819d5d11836f365bb.table.json","ncols":3,"nrows":243,"_type":"table-file"},"validation_f1":0.9231,"ap_comparison_plot_table":{"path":"media/table/ap_comparison_plot_table_487_d9d08e4984cc41c0643a.table.json","ncols":3,"nrows":243,"_type":"table-file","sha256":"d9d08e4984cc41c0643ac1a562e707e193fc33e928a222e455d79e218f464d37","size":5909,"artifact_path":"wandb-client-artifact://z2bvaz9nqgdzs39z2zotd084dskdsj6im4cxoisr6hha2iioq3bv8ce9jecov7dqgx7eqtmzx6qu20xtfp2oxyym0p14kkdvduht2wod1kw4252a33l9fohc5svgukvl/ap_comparison_plot_table.table.json","_latest_artifact_path":"wandb-client-artifact://ko1xlaclar86wodc4c5o06jp9nme5rhew4qbybokf4udd20a6ufsnqnd1ago5xjt97dk64l01rvf0p4gzz3ogu613zlmce1xpjxwcgpk6xc5yha9pcj7c9bk411tfbc7:latest/ap_comparison_plot_table.table.json"},"train_recall":1,"accuracy_comparison_plot_table":{"ncols":3,"nrows":243,"_type":"table-file","sha256":"916b1fff0f38f5778416d8f94517d4213dd43c35367f11746406f8122f9162b0","size":5770,"artifact_path":"wandb-client-artifact://e5a3n4g9fz4vwyyigt8x098gk37xwq39nyh4qil7krpirmatqvx6mepvoncq5fgisugcpxp1dz0dd8vkrng1jslt0h6m6z3n12rq4vs7mtg13u47442cpfk1hgy2chvo/accuracy_comparison_plot_table.table.json","_latest_artifact_path":"wandb-client-artifact://i2846lanw9lqj8df1t5ffuoo7cvabvvyuhwq6e2fs95o8m6ak3j4ixxlz3mx3rydwdxkdnx9kappjt4j1r9niuy9so4aupz0isa12q6kcz2ljtbsymcwibo5j3gc2c4r:latest/accuracy_comparison_plot_table.table.json","path":"media/table/accuracy_comparison_plot_table_486_916b1fff0f38f5778416.table.json"},"train_precision":0.9455,"validation_auc":0.6667,"validation_precision":0.8571,"_timestamp":1.7440531521102602e+09,"validation_recall":1,"_wandb":{"runtime":101},"_step":491,"validation_ap":0.9484,"train_ap":0.9996,"test_f1":0.8571}